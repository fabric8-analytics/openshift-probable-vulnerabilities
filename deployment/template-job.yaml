apiVersion: v1
kind: Template
labels:
  template: probable-vulnerabilities-inference
metadata:
  name: probable-vulnerabilities-inference
  annotations:
    description: probable-vulnerabilities-inference
objects:
- apiVersion: batch/v1
  kind: Job
  metadata:
    name: bert-inference
  spec:
    replicas: "${{REPLICAS}}"
    backoffLimit: 5
    template:
      metadata:
        name: bert-inference
      spec:
        restartPolicy: OnFailure
        volumes:
        - name: credentials
          secret:
            secretName: google-services-secret
            items:
            -  key: google-services.json
               path: gcloud/google-services.json
        containers:
        - env:
          - name: AWS_BUCKET_NAME_INFERENCE
            value: ${AWS_BUCKET_NAME_INFERENCE}
          - name: AWS_BUCKET_NAME_MODEL
            value: ${AWS_BUCKET_NAME_MODEL}
          - name: DAYS
            value: ${DAYS}
          - name: CVE_MODEL
            value: ${CVE_MODEL}
          - name: OSA_API_SERVER_HOST
            value: ${OSA_API_SERVER_HOST}
          - name: OSA_API_SERVER_PORT
            value: ${OSA_API_SERVER_PORT}
          - name: BIGQUERY_CREDENTIALS_FILEPATH
            value: "/etc/credentials/gcloud/google-services.json"
          - name: AWS_ACCESS_KEY_ID
            valueFrom:
              secretKeyRef:
                name: aws
                key: aws_access_key_id
          - name: AWS_SECRET_ACCESS_KEY
            valueFrom:
              secretKeyRef:
                name: aws
                key: aws_secret_access_key
          volumeMounts:
            - name: credentials
              mountPath: "/etc/credentials/"
              readOnly: true
          image: "${DOCKER_REGISTRY}/${DOCKER_IMAGE}:${IMAGE_TAG}"
          name: openshift-probable-vulnerabilities
          resources:
            requests:
              cpu: ${CPU_REQUEST}
              memory: ${MEMORY_REQUEST}
            limits:
              cpu: ${CPU_LIMIT}
              memory: ${MEMORY_LIMIT}

parameters:
- description: CPU request
  displayName: CPU request
  required: true
  name: CPU_REQUEST
  value: "125m"

- description: CPU limit
  displayName: CPU limit
  required: true
  name: CPU_LIMIT
  value: "4"

- description: Memory request
  displayName: Memory request
  required: true
  name: MEMORY_REQUEST
  value: "6Gi"

- description: Memory limit
  displayName: Memory limit
  required: true
  name: MEMORY_LIMIT
  value: "8Gi"

- description: Docker registry where the image is
  displayName: Docker registry
  required: true
  name: DOCKER_REGISTRY
  value: "docker.io"

- description: Docker image to use
  displayName: Docker image
  required: true
  name: DOCKER_IMAGE
  value: "rajusem/bert-inference"

- description: Image tag
  displayName: Image tag
  required: true
  name: IMAGE_TAG
  value: "latest"

- description: Number of deployment replicas
  displayName: Number of deployment replicas
  required: true
  name: REPLICAS
  value: "1"

- description: "The number of days for which the inference has to be run."
  displayName: Days for which report needs to be run
  required: true
  name: DAYS
  value: "7"

- displayName: "Model bucket Name"
  description: Name of the bucket which contains the model
  required: true
  name: AWS_BUCKET_NAME_MODEL
  value: "avgupta-dev-gokube-triage"

- description: "Bucket to which the results of the inference will be uploaded"
  displayName: Inference bucket name
  required: true
  name: AWS_BUCKET_NAME_INFERENCE
  value: "rzalavad-inference-output"

- description: "The CVE model type to use for inference, accepted values - bert/bert_torch/gru"
  displayName: CVE Model Name
  required: true
  name: CVE_MODEL
  value: "bert_torch"

- description: "OSA API Server Host"
  displayName: OSA API Server Host
  required: true
  name: OSA_API_SERVER_HOST
  value: "osa-api-server"

- description: "OSA API Server Port"
  displayName: OSA API Server Port
  required: true
  name: OSA_API_SERVER_PORT
  value: "5000"

